{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e0132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RMI (Recursive Model Index) Implementation\n",
      "Translated from Rust implementation\n",
      "======================================================================\n",
      "\n",
      "1. Creating synthetic dataset...\n",
      "Created 1000000 data points\n",
      "\n",
      "======================================================================\n",
      "2. Training RMI: linear,linear with branching factor 1000\n",
      "======================================================================\n",
      "Training top-level linear model...\n",
      "Training second-level linear models (num models = 1000)...\n",
      "Computing lower bound corrections...\n",
      "Fixing empty models...\n",
      "Computing last level errors...\n",
      "Evaluating RMI...\n",
      "\n",
      "RMI Training Complete!\n",
      "Build time: 5.543s\n",
      "Average error: 1841.99\n",
      "Max error: 38888\n",
      "Average log2 error: 6.352\n",
      "Max log2 error: 15.247\n",
      "\n",
      "3. Testing predictions...\n",
      "\n",
      "=== Benchmarking RMI ===\n",
      "Tested 1000 keys\n",
      "Average search range: 3015.47\n",
      "Prediction accuracy: 99.80%\n",
      "Avg log2(search range): 11.559\n",
      "\n",
      "======================================================================\n",
      "2. Training RMI: robust_linear,linear with branching factor 1000\n",
      "======================================================================\n",
      "Training top-level robust_linear model...\n",
      "Training second-level linear models (num models = 1000)...\n",
      "Computing lower bound corrections...\n",
      "Fixing empty models...\n",
      "Computing last level errors...\n",
      "Evaluating RMI...\n",
      "\n",
      "RMI Training Complete!\n",
      "Build time: 13.794s\n",
      "Average error: 1864.63\n",
      "Max error: 39129\n",
      "Average log2 error: 6.357\n",
      "Max log2 error: 15.256\n",
      "\n",
      "3. Testing predictions...\n",
      "\n",
      "=== Benchmarking RMI ===\n",
      "Tested 1000 keys\n",
      "Average search range: 3099.41\n",
      "Prediction accuracy: 100.00%\n",
      "Avg log2(search range): 11.598\n",
      "\n",
      "======================================================================\n",
      "2. Training RMI: cubic,linear with branching factor 1000\n",
      "======================================================================\n",
      "Training top-level cubic model...\n",
      "Training second-level linear models (num models = 1000)...\n",
      "Computing lower bound corrections...\n",
      "Fixing empty models...\n",
      "Computing last level errors...\n",
      "Evaluating RMI...\n",
      "\n",
      "RMI Training Complete!\n",
      "Build time: 10.371s\n",
      "Average error: 31.37\n",
      "Max error: 67\n",
      "Average log2 error: 5.934\n",
      "Max log2 error: 6.066\n",
      "\n",
      "3. Testing predictions...\n",
      "\n",
      "=== Benchmarking RMI ===\n",
      "Tested 1000 keys\n",
      "Average search range: 63.80\n",
      "Prediction accuracy: 100.00%\n",
      "Avg log2(search range): 6.018\n",
      "\n",
      "======================================================================\n",
      "2. Training RMI: linear_spline,linear with branching factor 1000\n",
      "======================================================================\n",
      "Training top-level linear_spline model...\n",
      "Training second-level linear models (num models = 1000)...\n",
      "Computing lower bound corrections...\n",
      "Fixing empty models...\n",
      "Computing last level errors...\n",
      "Evaluating RMI...\n",
      "\n",
      "RMI Training Complete!\n",
      "Build time: 6.189s\n",
      "Average error: 37.02\n",
      "Max error: 1000000\n",
      "Average log2 error: 6.159\n",
      "Max log2 error: 19.932\n",
      "\n",
      "3. Testing predictions...\n",
      "\n",
      "=== Benchmarking RMI ===\n",
      "Tested 1000 keys\n",
      "Average search range: 74.63\n",
      "Prediction accuracy: 100.00%\n",
      "Avg log2(search range): 6.241\n",
      "\n",
      "======================================================================\n",
      "RESULTS COMPARISON\n",
      "======================================================================\n",
      "Config                    Branch   Build(s)   AvgErr     MaxErr     AvgLog2    SearchRng \n",
      "----------------------------------------------------------------------\n",
      "linear,linear             1000     5.543      1841.99    38888      6.352      3015.47   \n",
      "robust_linear,linear      1000     13.794     1864.63    39129      6.357      3099.41   \n",
      "cubic,linear              1000     10.371     31.37      67         5.934      63.80     \n",
      "linear_spline,linear      1000     6.189      37.02      1000000    6.159      74.63     \n",
      "\n",
      "======================================================================\n",
      "Done!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RMI (Recursive Model Index) Implementation in Python\n",
    "Rust implementation at: https://github.com/learnedsystems/RMI\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Union, Iterator, Callable\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import math\n",
    "from enum import Enum\n",
    "import bisect\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/models/mod.rs\n",
    "# Model base classes and type definitions\n",
    "# =============================================================================\n",
    "\n",
    "class ModelDataType(Enum):\n",
    "    INT = \"uint64_t\"\n",
    "    INT128 = \"uint128_t\"\n",
    "    FLOAT = \"double\"\n",
    "\n",
    "class ModelInput:\n",
    "    \"\"\"From: rmi_lib/src/models/mod.rs\"\"\"\n",
    "    def __init__(self, value: Union[int, float]):\n",
    "        if isinstance(value, (int, np.integer)):\n",
    "            self.value = int(value)\n",
    "            self.is_float = False\n",
    "        else:\n",
    "            self.value = float(value)\n",
    "            self.is_float = True\n",
    "    \n",
    "    def as_float(self) -> float:\n",
    "        return float(self.value)\n",
    "    \n",
    "    def as_int(self) -> int:\n",
    "        return int(self.value)\n",
    "\n",
    "class RMITrainingData:\n",
    "    \"\"\"\n",
    "    From: rmi_lib/src/models/mod.rs\n",
    "    Training data container for RMI\n",
    "    \"\"\"\n",
    "    def __init__(self, data: List[Tuple[Union[int, float], int]]):\n",
    "        self.data = sorted(data, key=lambda x: x[0])\n",
    "        self.scale = 1.0\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def set_scale(self, scale: float):\n",
    "        self.scale = scale\n",
    "    \n",
    "    def get(self, idx: int) -> Tuple[Union[int, float], int]:\n",
    "        key, offset = self.data[idx]\n",
    "        if abs(self.scale - 1.0) > 1e-10:\n",
    "            return (key, int(offset * self.scale))\n",
    "        return (key, offset)\n",
    "    \n",
    "    def get_key(self, idx: int) -> Union[int, float]:\n",
    "        return self.data[idx][0]\n",
    "    \n",
    "    def iter(self) -> Iterator[Tuple[Union[int, float], int]]:\n",
    "        \"\"\"Iterator with scale applied\"\"\"\n",
    "        for key, offset in self.data:\n",
    "            if abs(self.scale - 1.0) > 1e-10:\n",
    "                yield (key, int(offset * self.scale))\n",
    "            else:\n",
    "                yield (key, offset)\n",
    "    \n",
    "    def iter_model_input(self) -> Iterator[Tuple[ModelInput, int]]:\n",
    "        \"\"\"Iterator yielding ModelInput objects\"\"\"\n",
    "        for key, offset in self.iter():\n",
    "            yield (ModelInput(key), offset)\n",
    "    \n",
    "    def iter_unique(self) -> Iterator[Tuple[Union[int, float], int]]:\n",
    "        \"\"\"Iterator that removes duplicate keys\"\"\"\n",
    "        if len(self.data) == 0:\n",
    "            return\n",
    "        last_key = None\n",
    "        for key, offset in self.iter():\n",
    "            if last_key is None or key != last_key:\n",
    "                yield (key, offset)\n",
    "                last_key = key\n",
    "    \n",
    "    def lower_bound_by(self, cmp_func: Callable) -> int:\n",
    "        \"\"\"From: rmi_lib/src/models/mod.rs - binary search for lower bound\"\"\"\n",
    "        size = len(self)\n",
    "        if size == 0:\n",
    "            return 0\n",
    "        \n",
    "        base = 0\n",
    "        while size > 1:\n",
    "            half = size // 2\n",
    "            mid = base + half\n",
    "            cmp_result = cmp_func(self.get(mid))\n",
    "            if cmp_result < 0:  # Less\n",
    "                base = mid\n",
    "            size -= half\n",
    "        \n",
    "        cmp_result = cmp_func(self.get(base))\n",
    "        base += (1 if cmp_result < 0 else 0)\n",
    "        return base\n",
    "    \n",
    "    def soft_copy(self):\n",
    "        \"\"\"Create a shallow copy with same data\"\"\"\n",
    "        new_data = RMITrainingData(self.data[:])\n",
    "        new_data.scale = self.scale\n",
    "        return new_data\n",
    "\n",
    "class Model(ABC):\n",
    "    \"\"\"\n",
    "    From: rmi_lib/src/models/mod.rs\n",
    "    Base class for all RMI models\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        pass\n",
    "    \n",
    "    def predict_to_int(self, inp: ModelInput) -> int:\n",
    "        return max(0, int(math.floor(self.predict_to_float(inp))))\n",
    "    \n",
    "    @abstractmethod\n",
    "    def input_type(self) -> ModelDataType:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def output_type(self) -> ModelDataType:\n",
    "        pass\n",
    "    \n",
    "    def needs_bounds_check(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def set_to_constant_model(self, constant: int) -> bool:\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/models/linear.rs\n",
    "# Linear regression models\n",
    "# =============================================================================\n",
    "\n",
    "class LinearModel(Model):\n",
    "    \"\"\"From: rmi_lib/src/models/linear.rs\"\"\"\n",
    "    def __init__(self, data: RMITrainingData):\n",
    "        self.intercept, self.slope = self._slr(data)\n",
    "    \n",
    "    def _slr(self, data: RMITrainingData) -> Tuple[float, float]:\n",
    "        \"\"\"Simple linear regression using online algorithm\"\"\"\n",
    "        mean_x = 0.0\n",
    "        mean_y = 0.0\n",
    "        c = 0.0\n",
    "        n = 0\n",
    "        m2 = 0.0\n",
    "        data_size = 0\n",
    "        \n",
    "        for x, y in data.iter():\n",
    "            n += 1\n",
    "            dx = float(x) - mean_x\n",
    "            mean_x += dx / n\n",
    "            mean_y += (float(y) - mean_y) / n\n",
    "            c += dx * (float(y) - mean_y)\n",
    "            \n",
    "            dx2 = float(x) - mean_x\n",
    "            m2 += dx * dx2\n",
    "            data_size += 1\n",
    "        \n",
    "        if data_size == 0:\n",
    "            return (0.0, 0.0)\n",
    "        if data_size == 1:\n",
    "            return (mean_y, 0.0)\n",
    "        \n",
    "        cov = c / (n - 1)\n",
    "        var = m2 / (n - 1)\n",
    "        \n",
    "        if var == 0.0:\n",
    "            return (mean_y, 0.0)\n",
    "        \n",
    "        beta = cov / var\n",
    "        alpha = mean_y - beta * mean_x\n",
    "        \n",
    "        return (alpha, beta)\n",
    "    \n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        return self.slope * inp.as_float() + self.intercept\n",
    "    \n",
    "    def input_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def output_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def set_to_constant_model(self, constant: int) -> bool:\n",
    "        self.intercept = float(constant)\n",
    "        self.slope = 0.0\n",
    "        return True\n",
    "\n",
    "class RobustLinearModel(Model):\n",
    "    \"\"\"From: rmi_lib/src/models/linear.rs\"\"\"\n",
    "    def __init__(self, data: RMITrainingData):\n",
    "        total_items = len(data)\n",
    "        if total_items == 0:\n",
    "            self.intercept, self.slope = (0.0, 0.0)\n",
    "            return\n",
    "        \n",
    "        # Skip 0.01% of data from each end for robustness\n",
    "        bnd = max(1, int(total_items * 0.0001))\n",
    "        \n",
    "        # Need at least bnd*2+1 items\n",
    "        if bnd * 2 + 1 >= total_items:\n",
    "            # Not enough data, use regular linear\n",
    "            self.intercept, self.slope = LinearModel(data)._slr(data)\n",
    "            return\n",
    "        \n",
    "        # Create iterator skipping first and last bnd items\n",
    "        subset = []\n",
    "        for i, item in enumerate(data.iter()):\n",
    "            if i < bnd:\n",
    "                continue\n",
    "            if i >= total_items - bnd:\n",
    "                break\n",
    "            subset.append(item)\n",
    "        \n",
    "        subset_data = RMITrainingData(subset)\n",
    "        self.intercept, self.slope = LinearModel(subset_data)._slr(subset_data)\n",
    "    \n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        return self.slope * inp.as_float() + self.intercept\n",
    "    \n",
    "    def input_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def output_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def set_to_constant_model(self, constant: int) -> bool:\n",
    "        self.intercept = float(constant)\n",
    "        self.slope = 0.0\n",
    "        return True\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/models/linear_spline.rs\n",
    "# Linear spline model\n",
    "# =============================================================================\n",
    "\n",
    "class LinearSplineModel(Model):\n",
    "    \"\"\"From: rmi_lib/src/models/linear_spline.rs\"\"\"\n",
    "    def __init__(self, data: RMITrainingData):\n",
    "        self.intercept, self.slope = self._linear_splines(data)\n",
    "    \n",
    "    def _linear_splines(self, data: RMITrainingData) -> Tuple[float, float]:\n",
    "        if len(data) == 0:\n",
    "            return (0.0, 0.0)\n",
    "        if len(data) == 1:\n",
    "            return (float(data.get(0)[1]), 0.0)\n",
    "        \n",
    "        first_pt = data.get(0)\n",
    "        last_pt = data.get(len(data) - 1)\n",
    "        \n",
    "        if first_pt[0] == last_pt[0]:\n",
    "            return (float(data.get(0)[1]), 0.0)\n",
    "        \n",
    "        slope = (float(first_pt[1]) - float(last_pt[1])) / (float(first_pt[0]) - float(last_pt[0]))\n",
    "        intercept = float(first_pt[1]) - slope * float(first_pt[0])\n",
    "        \n",
    "        return (intercept, slope)\n",
    "    \n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        return self.slope * inp.as_float() + self.intercept\n",
    "    \n",
    "    def input_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def output_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def set_to_constant_model(self, constant: int) -> bool:\n",
    "        self.intercept = float(constant)\n",
    "        self.slope = 0.0\n",
    "        return True\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/models/cubic_spline.rs\n",
    "# Cubic spline model\n",
    "# =============================================================================\n",
    "\n",
    "class CubicSplineModel(Model):\n",
    "    \"\"\"From: rmi_lib/src/models/cubic_spline.rs\"\"\"\n",
    "    def __init__(self, data: RMITrainingData):\n",
    "        self.a, self.b, self.c, self.d = self._cubic(data)\n",
    "        \n",
    "        # Check against linear model - sometimes cubic doesn't work well\n",
    "        linear = LinearSplineModel(data)\n",
    "        \n",
    "        our_error = 0.0\n",
    "        lin_error = 0.0\n",
    "        \n",
    "        for x, y in data.iter_model_input():\n",
    "            c_pred = self.predict_to_float(x)\n",
    "            l_pred = linear.predict_to_float(x)\n",
    "            \n",
    "            our_error += abs(c_pred - float(y))\n",
    "            lin_error += abs(l_pred - float(y))\n",
    "        \n",
    "        if lin_error < our_error:\n",
    "            # Use linear instead\n",
    "            self.a = 0.0\n",
    "            self.b = 0.0\n",
    "            self.c = linear.slope\n",
    "            self.d = linear.intercept\n",
    "    \n",
    "    def _cubic(self, data: RMITrainingData) -> Tuple[float, float, float, float]:\n",
    "        if len(data) == 0:\n",
    "            return (0.0, 0.0, 1.0, 0.0)\n",
    "        if len(data) == 1:\n",
    "            return (0.0, 0.0, 0.0, float(data.get(0)[1]))\n",
    "        \n",
    "        # Check for unique values\n",
    "        candidate = data.get(0)[0]\n",
    "        uniq = any(x != candidate for x, _ in data.iter())\n",
    "        if not uniq:\n",
    "            return (0.0, 0.0, 0.0, float(data.get(0)[1]))\n",
    "        \n",
    "        first_pt = data.get(0)\n",
    "        last_pt = data.get(len(data) - 1)\n",
    "        xmin, ymin = float(first_pt[0]), float(first_pt[1])\n",
    "        xmax, ymax = float(last_pt[0]), float(last_pt[1])\n",
    "        \n",
    "        x1, y1 = 0.0, 0.0\n",
    "        x2, y2 = 1.0, 1.0\n",
    "        \n",
    "        # Find first point with scaled x > 0\n",
    "        m1 = None\n",
    "        for xn, yn in data.iter():\n",
    "            sxn = (float(xn) - xmin) / (xmax - xmin)\n",
    "            if sxn > 0.0:\n",
    "                syn = (float(yn) - ymin) / (ymax - ymin)\n",
    "                m1 = (syn - y1) / (sxn - x1)\n",
    "                break\n",
    "        \n",
    "        if m1 is None:\n",
    "            m1 = 0.0\n",
    "        \n",
    "        # Find last point with scaled x < 1\n",
    "        m2 = None\n",
    "        for i in range(len(data) - 1, -1, -1):\n",
    "            xp, yp = data.get(i)\n",
    "            sxp = (float(xp) - xmin) / (xmax - xmin)\n",
    "            if sxp < 1.0:\n",
    "                syp = (float(yp) - ymin) / (ymax - ymin)\n",
    "                m2 = (y2 - syp) / (x2 - sxp)\n",
    "                break\n",
    "        \n",
    "        if m2 is None:\n",
    "            m2 = 0.0\n",
    "        \n",
    "        # Keep monotonic\n",
    "        if m1**2 + m2**2 > 9.0:\n",
    "            tau = 3.0 / math.sqrt(m1**2 + m2**2)\n",
    "            m1 *= tau\n",
    "            m2 *= tau\n",
    "        \n",
    "        # Compute coefficients\n",
    "        a = (m1 + m2 - 2.0) / (xmax - xmin)**3\n",
    "        b = -(xmax * (2.0*m1 + m2 - 3.0) + xmin * (m1 + 2.0*m2 - 3.0)) / (xmax - xmin)**3\n",
    "        c = (m1*xmax**2 + m2*xmin**2 + xmax*xmin*(2.0*m1 + 2.0*m2 - 6.0)) / (xmax - xmin)**3\n",
    "        d = -xmin * (m1*xmax**2 + xmax*xmin*(m2 - 3.0) + xmin**2) / (xmax - xmin)**3\n",
    "        \n",
    "        a *= ymax - ymin\n",
    "        b *= ymax - ymin\n",
    "        c *= ymax - ymin\n",
    "        d *= ymax - ymin\n",
    "        d += ymin\n",
    "        \n",
    "        return (a, b, c, d)\n",
    "    \n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        val = inp.as_float()\n",
    "        # Use FMA-like computation\n",
    "        v1 = self.a * val + self.b\n",
    "        v2 = v1 * val + self.c\n",
    "        v3 = v2 * val + self.d\n",
    "        return v3\n",
    "    \n",
    "    def input_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def output_type(self) -> ModelDataType:\n",
    "        return ModelDataType.FLOAT\n",
    "    \n",
    "    def set_to_constant_model(self, constant: int) -> bool:\n",
    "        self.a = 0.0\n",
    "        self.b = 0.0\n",
    "        self.c = 0.0\n",
    "        self.d = float(constant)\n",
    "        return True\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/models/radix.rs\n",
    "# Radix models\n",
    "# =============================================================================\n",
    "\n",
    "def num_bits(largest_target: int) -> int:\n",
    "    \"\"\"From: rmi_lib/src/models/utils.rs\"\"\"\n",
    "    nbits = 0\n",
    "    while (1 << (nbits + 1)) - 1 <= largest_target:\n",
    "        nbits += 1\n",
    "    assert nbits >= 1\n",
    "    return nbits\n",
    "\n",
    "def common_prefix_size(data: RMITrainingData) -> int:\n",
    "    \"\"\"From: rmi_lib/src/models/utils.rs\"\"\"\n",
    "    any_ones = 0\n",
    "    no_ones = (1 << 64) - 1\n",
    "    \n",
    "    for x, _ in data.iter_model_input():\n",
    "        val = x.as_int()\n",
    "        any_ones |= val\n",
    "        no_ones &= val\n",
    "    \n",
    "    any_zeros = ~no_ones & ((1 << 64) - 1)\n",
    "    prefix_bits = any_zeros ^ any_ones\n",
    "    \n",
    "    # Count leading zeros\n",
    "    prefix_bits &= ((1 << 64) - 1)\n",
    "    if prefix_bits == 0:\n",
    "        return 64\n",
    "    \n",
    "    leading_zeros = 0\n",
    "    test_bit = 1 << 63\n",
    "    while test_bit > 0 and (~prefix_bits & test_bit):\n",
    "        leading_zeros += 1\n",
    "        test_bit >>= 1\n",
    "    \n",
    "    return leading_zeros\n",
    "\n",
    "class RadixModel(Model):\n",
    "    \"\"\"From: rmi_lib/src/models/radix.rs\"\"\"\n",
    "    def __init__(self, data: RMITrainingData):\n",
    "        if len(data) == 0:\n",
    "            self.left_shift = 0\n",
    "            self.num_bits = 0\n",
    "            return\n",
    "        \n",
    "        largest_value = max(y for _, y in data.iter())\n",
    "        bits = num_bits(largest_value)\n",
    "        common_prefix = common_prefix_size(data)\n",
    "        \n",
    "        self.left_shift = common_prefix\n",
    "        self.num_bits = bits\n",
    "    \n",
    "    def predict_to_int(self, inp: ModelInput) -> int:\n",
    "        as_int = inp.as_int()\n",
    "        res = (as_int << self.left_shift) >> (64 - self.num_bits)\n",
    "        return res & ((1 << 64) - 1)\n",
    "    \n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        return float(self.predict_to_int(inp))\n",
    "    \n",
    "    def input_type(self) -> ModelDataType:\n",
    "        return ModelDataType.INT\n",
    "    \n",
    "    def output_type(self) -> ModelDataType:\n",
    "        return ModelDataType.INT\n",
    "    \n",
    "    def needs_bounds_check(self) -> bool:\n",
    "        return False\n",
    "\n",
    "class RadixTable(Model):\n",
    "    \"\"\"From: rmi_lib/src/models/radix.rs\"\"\"\n",
    "    def __init__(self, data: RMITrainingData, bits: int):\n",
    "        self.prefix_bits = common_prefix_size(data)\n",
    "        self.table_bits = bits\n",
    "        self.hint_table = [0] * (1 << bits)\n",
    "        \n",
    "        last_radix = 0\n",
    "        for inp, y in data.iter_model_input():\n",
    "            x = inp.as_int()\n",
    "            num_bits = 0 if self.prefix_bits + bits > 64 else 64 - (self.prefix_bits + bits)\n",
    "            current_radix = ((x << self.prefix_bits) >> self.prefix_bits) >> num_bits\n",
    "            \n",
    "            if current_radix == last_radix:\n",
    "                continue\n",
    "            \n",
    "            self.hint_table[int(current_radix)] = y\n",
    "            \n",
    "            for i in range(int(last_radix) + 1, int(current_radix)):\n",
    "                self.hint_table[i] = y\n",
    "            \n",
    "            last_radix = current_radix\n",
    "        \n",
    "        for i in range(int(last_radix) + 1, len(self.hint_table)):\n",
    "            self.hint_table[i] = len(self.hint_table)\n",
    "    \n",
    "    def predict_to_int(self, inp: ModelInput) -> int:\n",
    "        as_int = inp.as_int()\n",
    "        num_bits = 0 if self.prefix_bits + self.table_bits > 64 else 64 - (self.prefix_bits + self.table_bits)\n",
    "        res = ((as_int << self.prefix_bits) >> self.prefix_bits) >> num_bits\n",
    "        idx = self.hint_table[int(res)]\n",
    "        return idx\n",
    "    \n",
    "    def predict_to_float(self, inp: ModelInput) -> float:\n",
    "        return float(self.predict_to_int(inp))\n",
    "    \n",
    "    def input_type(self) -> ModelDataType:\n",
    "        return ModelDataType.INT\n",
    "    \n",
    "    def output_type(self) -> ModelDataType:\n",
    "        return ModelDataType.INT\n",
    "    \n",
    "    def needs_bounds_check(self) -> bool:\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/train/lower_bound_correction.rs\n",
    "# Lower bound correction for empty models\n",
    "# =============================================================================\n",
    "\n",
    "class LowerBoundCorrection:\n",
    "    \"\"\"From: rmi_lib/src/train/lower_bound_correction.rs\"\"\"\n",
    "    def __init__(self, pred_func: Callable, num_leaf_models: int, data: RMITrainingData):\n",
    "        self.first = [None] * num_leaf_models\n",
    "        self.last = [None] * num_leaf_models\n",
    "        self.next = [(0, 0)] * num_leaf_models\n",
    "        self.prev = [(0, 0)] * num_leaf_models\n",
    "        self.run_lengths = [0] * num_leaf_models\n",
    "        \n",
    "        last_target = 0\n",
    "        current_run_length = 0\n",
    "        current_run_key = data.get_key(0)\n",
    "        \n",
    "        for x, y in data.iter():\n",
    "            leaf_idx = pred_func(x)\n",
    "            target = min(num_leaf_models - 1, leaf_idx)\n",
    "            \n",
    "            if target == last_target and x == current_run_key:\n",
    "                current_run_length += 1\n",
    "            elif target != last_target or x != current_run_key:\n",
    "                self.run_lengths[last_target] = max(\n",
    "                    self.run_lengths[last_target], current_run_length\n",
    "                )\n",
    "                current_run_length = 1\n",
    "                current_run_key = x\n",
    "                last_target = target\n",
    "            \n",
    "            if self.first[target] is None:\n",
    "                self.first[target] = (y, x)\n",
    "            self.last[target] = (y, x)\n",
    "        \n",
    "        # Compute next_for_leaf\n",
    "        idx = 0\n",
    "        while idx < num_leaf_models:\n",
    "            next_found = None\n",
    "            for i in range(idx + 1, num_leaf_models):\n",
    "                if self.first[i] is not None:\n",
    "                    next_found = (i, self.first[i])\n",
    "                    break\n",
    "            \n",
    "            if next_found:\n",
    "                next_leaf_idx, val = next_found\n",
    "                for i in range(idx, next_leaf_idx):\n",
    "                    self.next[i] = val\n",
    "                idx = next_leaf_idx\n",
    "            else:\n",
    "                for i in range(idx, num_leaf_models):\n",
    "                    self.next[i] = (len(data), data.get_key(len(data) - 1) if len(data) > 0 else 0)\n",
    "                break\n",
    "        \n",
    "        # Compute prev_for_leaf\n",
    "        idx = num_leaf_models - 1\n",
    "        while idx > 0:\n",
    "            prev_found = None\n",
    "            for i in range(idx - 1, -1, -1):\n",
    "                if self.last[i] is not None:\n",
    "                    prev_found = (i, self.last[i])\n",
    "                    break\n",
    "            \n",
    "            if prev_found:\n",
    "                prev_leaf_idx, val = prev_found\n",
    "                for i in range(prev_leaf_idx + 1, idx + 1):\n",
    "                    self.prev[i] = val\n",
    "                idx = prev_leaf_idx\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def first_key(self, leaf_idx: int) -> Optional[Union[int, float]]:\n",
    "        return self.first[leaf_idx][1] if self.first[leaf_idx] else None\n",
    "    \n",
    "    def last_key(self, leaf_idx: int) -> Optional[Union[int, float]]:\n",
    "        return self.last[leaf_idx][1] if self.last[leaf_idx] else None\n",
    "    \n",
    "    def next_index(self, leaf_idx: int) -> int:\n",
    "        return self.next[leaf_idx][0]\n",
    "    \n",
    "    def prev_key(self, leaf_idx: int) -> Union[int, float]:\n",
    "        return self.prev[leaf_idx][1]\n",
    "    \n",
    "    def longest_run(self, leaf_idx: int) -> int:\n",
    "        return self.run_lengths[leaf_idx]\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/train/two_layer.rs\n",
    "# Two-layer RMI training\n",
    "# =============================================================================\n",
    "\n",
    "def error_between(v1: int, v2: int, max_pred: int) -> int:\n",
    "    \"\"\"From: rmi_lib/src/train/two_layer.rs\"\"\"\n",
    "    pred1 = min(v1, max_pred)\n",
    "    pred2 = min(v2, max_pred)\n",
    "    return max(pred1, pred2) - min(pred1, pred2)\n",
    "\n",
    "def train_model(model_type: str, data: RMITrainingData) -> Model:\n",
    "    \"\"\"From: rmi_lib/src/train/mod.rs\"\"\"\n",
    "    model_map = {\n",
    "        'linear': LinearModel,\n",
    "        'robust_linear': RobustLinearModel,\n",
    "        'linear_spline': LinearSplineModel,\n",
    "        'cubic': CubicSplineModel,\n",
    "        'radix': RadixModel,\n",
    "    }\n",
    "    \n",
    "    if model_type.startswith('radix') and model_type != 'radix':\n",
    "        bits = int(model_type[5:])\n",
    "        return RadixTable(data, bits)\n",
    "    \n",
    "    if model_type not in model_map:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    return model_map[model_type](data)\n",
    "\n",
    "@dataclass\n",
    "class TrainedRMI:\n",
    "    \"\"\"From: rmi_lib/src/train/mod.rs\"\"\"\n",
    "    num_rmi_rows: int\n",
    "    num_data_rows: int\n",
    "    model_avg_error: float\n",
    "    model_avg_l2_error: float\n",
    "    model_avg_log2_error: float\n",
    "    model_max_error: int\n",
    "    model_max_error_idx: int\n",
    "    model_max_log2_error: float\n",
    "    last_layer_max_l1s: List[int]\n",
    "    rmi: List[List[Model]]\n",
    "    models: str\n",
    "    branching_factor: int\n",
    "    build_time: float\n",
    "    \n",
    "    def predict(self, key: Union[int, float]) -> Tuple[int, int]:\n",
    "        \"\"\"Predict position and error for a key\"\"\"\n",
    "        inp = ModelInput(key)\n",
    "        \n",
    "        # First layer\n",
    "        model_idx = self.rmi[0][0].predict_to_int(inp)\n",
    "        \n",
    "        # Second layer\n",
    "        model_idx = min(len(self.rmi[1]) - 1, model_idx)\n",
    "        prediction = self.rmi[1][model_idx].predict_to_int(inp)\n",
    "        error = self.last_layer_max_l1s[model_idx]\n",
    "        \n",
    "        return (prediction, error)\n",
    "\n",
    "def build_models_from(\n",
    "    data: RMITrainingData,\n",
    "    top_model: Model,\n",
    "    model_type: str,\n",
    "    start_idx: int,\n",
    "    end_idx: int,\n",
    "    first_model_idx: int,\n",
    "    num_models: int\n",
    ") -> List[Model]:\n",
    "    \"\"\"From: rmi_lib/src/train/two_layer.rs\"\"\"\n",
    "    \n",
    "    assert end_idx > start_idx\n",
    "    assert end_idx <= len(data)\n",
    "    assert start_idx <= len(data)\n",
    "    \n",
    "    leaf_models = []\n",
    "    second_layer_data = []\n",
    "    last_target = first_model_idx\n",
    "    \n",
    "    # Get bounded iterator\n",
    "    for i, (x, y) in enumerate(data.iter()):\n",
    "        if i < start_idx:\n",
    "            continue\n",
    "        if i >= end_idx:\n",
    "            break\n",
    "        \n",
    "        model_pred = top_model.predict_to_int(ModelInput(x))\n",
    "        target = min(first_model_idx + num_models - 1, model_pred)\n",
    "        assert target >= last_target\n",
    "        \n",
    "        if target > last_target:\n",
    "            # Train previous model\n",
    "            last_item = second_layer_data[-1] if second_layer_data else None\n",
    "            second_layer_data.append((x, y))\n",
    "            \n",
    "            container = RMITrainingData(second_layer_data)\n",
    "            leaf_model = train_model(model_type, container)\n",
    "            leaf_models.append(leaf_model)\n",
    "            \n",
    "            # Add empty models for skipped indices\n",
    "            for _ in range(last_target + 1, target):\n",
    "                empty_data = RMITrainingData([])\n",
    "                leaf_models.append(train_model(model_type, empty_data))\n",
    "            \n",
    "            assert len(leaf_models) + first_model_idx == target\n",
    "            \n",
    "            second_layer_data = []\n",
    "            if last_item:\n",
    "                second_layer_data.append(last_item)\n",
    "        \n",
    "        second_layer_data.append((x, y))\n",
    "        last_target = target\n",
    "    \n",
    "    # Train last model\n",
    "    assert second_layer_data\n",
    "    container = RMITrainingData(second_layer_data)\n",
    "    leaf_model = train_model(model_type, container)\n",
    "    leaf_models.append(leaf_model)\n",
    "    \n",
    "    # Add remaining empty models\n",
    "    for _ in range(last_target + 1, first_model_idx + num_models):\n",
    "        empty_data = RMITrainingData([])\n",
    "        leaf_models.append(train_model(model_type, empty_data))\n",
    "    \n",
    "    assert len(leaf_models) == num_models\n",
    "    return leaf_models\n",
    "\n",
    "def train_two_layer(\n",
    "    data: RMITrainingData,\n",
    "    layer1_model: str,\n",
    "    layer2_model: str,\n",
    "    num_leaf_models: int\n",
    ") -> TrainedRMI:\n",
    "    \"\"\"From: rmi_lib/src/train/two_layer.rs\"\"\"\n",
    "    \n",
    "    num_rows = len(data)\n",
    "    \n",
    "    print(f\"Training top-level {layer1_model} model...\")\n",
    "    data.set_scale(num_leaf_models / num_rows)\n",
    "    top_model = train_model(layer1_model, data)\n",
    "    \n",
    "    print(f\"Training second-level {layer2_model} models (num models = {num_leaf_models})...\")\n",
    "    data.set_scale(1.0)\n",
    "    \n",
    "    # Find split point near middle\n",
    "    midpoint_model = num_leaf_models // 2\n",
    "    split_idx = data.lower_bound_by(\n",
    "        lambda x: -1 if top_model.predict_to_int(ModelInput(x[0])) < midpoint_model \n",
    "                  else (1 if top_model.predict_to_int(ModelInput(x[0])) > midpoint_model else 0)\n",
    "    )\n",
    "    \n",
    "    # Build leaf models\n",
    "    if split_idx >= len(data):\n",
    "        leaf_models = build_models_from(\n",
    "            data, top_model, layer2_model, 0, len(data), 0, num_leaf_models\n",
    "        )\n",
    "    else:\n",
    "        split_idx_target = min(\n",
    "            num_leaf_models - 1,\n",
    "            top_model.predict_to_int(ModelInput(data.get_key(split_idx)))\n",
    "        )\n",
    "        \n",
    "        first_half_models = split_idx_target\n",
    "        second_half_models = num_leaf_models - split_idx_target\n",
    "        \n",
    "        # Build first half\n",
    "        hf1 = build_models_from(\n",
    "            data, top_model, layer2_model, 0, split_idx, 0, first_half_models\n",
    "        )\n",
    "        \n",
    "        # Build second half\n",
    "        hf2 = build_models_from(\n",
    "            data, top_model, layer2_model, split_idx + 1, len(data),\n",
    "            split_idx_target, second_half_models\n",
    "        )\n",
    "        \n",
    "        leaf_models = hf1 + hf2\n",
    "    \n",
    "    print(\"Computing lower bound corrections...\")\n",
    "    lb_corrections = LowerBoundCorrection(\n",
    "        lambda x: top_model.predict_to_int(ModelInput(x)),\n",
    "        num_leaf_models,\n",
    "        data\n",
    "    )\n",
    "    \n",
    "    print(\"Fixing empty models...\")\n",
    "    # Replace empty models with constants\n",
    "    for idx in range(num_leaf_models - 1):\n",
    "        if lb_corrections.first_key(idx) is None:\n",
    "            upper_bound = lb_corrections.next_index(idx)\n",
    "            leaf_models[idx].set_to_constant_model(upper_bound)\n",
    "    \n",
    "    print(\"Computing last level errors...\")\n",
    "    # Compute errors for each leaf model\n",
    "    last_layer_max_l1s = [(0, 0)] * num_leaf_models\n",
    "    \n",
    "    for x, y in data.iter_model_input():\n",
    "        leaf_idx = top_model.predict_to_int(x)\n",
    "        target = min(num_leaf_models - 1, leaf_idx)\n",
    "        \n",
    "        pred = leaf_models[target].predict_to_int(x)\n",
    "        err = error_between(pred, y, len(data))\n",
    "        \n",
    "        cur_count, cur_max = last_layer_max_l1s[target]\n",
    "        last_layer_max_l1s[target] = (cur_count + 1, max(err, cur_max))\n",
    "    \n",
    "    # Adjust errors for lower bound correctness\n",
    "    for leaf_idx in range(num_leaf_models):\n",
    "        curr_err = last_layer_max_l1s[leaf_idx][1]\n",
    "        \n",
    "        # Upper error\n",
    "        idx_of_next, key_of_next = lb_corrections.next[leaf_idx]\n",
    "        key_minus_eps = key_of_next - (1 if isinstance(key_of_next, int) else 1e-10)\n",
    "        pred = leaf_models[leaf_idx].predict_to_int(ModelInput(key_minus_eps))\n",
    "        upper_error = error_between(pred, idx_of_next + 1, len(data))\n",
    "        \n",
    "        # Lower error\n",
    "        first_key_before = lb_corrections.prev_key(leaf_idx)\n",
    "        prev_idx = 0 if leaf_idx == 0 else leaf_idx - 1\n",
    "        first_idx = lb_corrections.next_index(prev_idx)\n",
    "        \n",
    "        key_plus_eps = first_key_before + (1 if isinstance(first_key_before, int) else 1e-10)\n",
    "        pred = leaf_models[leaf_idx].predict_to_int(ModelInput(key_plus_eps))\n",
    "        lower_error = error_between(pred, first_idx, len(data))\n",
    "        \n",
    "        new_err = max(curr_err, upper_error, lower_error) + lb_corrections.longest_run(leaf_idx)\n",
    "        \n",
    "        num_items = last_layer_max_l1s[leaf_idx][0]\n",
    "        last_layer_max_l1s[leaf_idx] = (num_items, new_err)\n",
    "    \n",
    "    print(\"Evaluating RMI...\")\n",
    "    # Compute statistics\n",
    "    model_max_error_idx, (_, model_max_error) = max(\n",
    "        enumerate(last_layer_max_l1s), key=lambda x: x[1][1]\n",
    "    )\n",
    "    \n",
    "    total_items = sum(n for n, _ in last_layer_max_l1s)\n",
    "    model_avg_error = sum(n * err for n, err in last_layer_max_l1s) / total_items\n",
    "    model_avg_l2_error = sum((n * err) ** 2 for n, err in last_layer_max_l1s) / total_items\n",
    "    model_avg_log2_error = sum(n * math.log2(2 * err + 2) for n, err in last_layer_max_l1s) / total_items\n",
    "    model_max_log2_error = math.log2(model_max_error) if model_max_error > 0 else 0.0\n",
    "    \n",
    "    final_errors = [err for _, err in last_layer_max_l1s]\n",
    "    \n",
    "    return TrainedRMI(\n",
    "        num_rmi_rows=len(data),\n",
    "        num_data_rows=len(data),\n",
    "        model_avg_error=model_avg_error,\n",
    "        model_avg_l2_error=model_avg_l2_error,\n",
    "        model_avg_log2_error=model_avg_log2_error,\n",
    "        model_max_error=model_max_error,\n",
    "        model_max_error_idx=model_max_error_idx,\n",
    "        model_max_log2_error=model_max_log2_error,\n",
    "        last_layer_max_l1s=final_errors,\n",
    "        rmi=[[top_model], leaf_models],\n",
    "        models=f\"{layer1_model},{layer2_model}\",\n",
    "        branching_factor=num_leaf_models,\n",
    "        build_time=0.0\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# From: rmi_lib/src/train/mod.rs\n",
    "# Main training function\n",
    "# =============================================================================\n",
    "\n",
    "def train(data: RMITrainingData, model_spec: str, branch_factor: int) -> TrainedRMI:\n",
    "    \"\"\"From: rmi_lib/src/train/mod.rs\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_list = model_spec.split(',')\n",
    "    if len(model_list) != 2:\n",
    "        raise ValueError(\"Only two-layer RMIs are currently supported\")\n",
    "    \n",
    "    layer1_model, layer2_model = model_list\n",
    "    \n",
    "    result = train_two_layer(data, layer1_model, layer2_model, branch_factor)\n",
    "    \n",
    "    build_time = time.time() - start_time\n",
    "    result.build_time = build_time\n",
    "    \n",
    "    print(f\"\\nRMI Training Complete!\")\n",
    "    print(f\"Build time: {build_time:.3f}s\")\n",
    "    print(f\"Average error: {result.model_avg_error:.2f}\")\n",
    "    print(f\"Max error: {result.model_max_error}\")\n",
    "    print(f\"Average log2 error: {result.model_avg_log2_error:.3f}\")\n",
    "    print(f\"Max log2 error: {result.model_max_log2_error:.3f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# =============================================================================\n",
    "# Example usage and testing\n",
    "# =============================================================================\n",
    "\n",
    "def load_binary_data(filename: str) -> RMITrainingData:\n",
    "    \"\"\"\n",
    "    Load binary data file in the format expected by RMI:\n",
    "    - First 8 bytes: number of items (uint64, little endian)\n",
    "    - Remaining bytes: data items (uint64 or uint32, little endian)\n",
    "    \"\"\"\n",
    "    import struct\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read number of items\n",
    "        num_items_bytes = f.read(8)\n",
    "        num_items = struct.unpack('<Q', num_items_bytes)[0]\n",
    "        \n",
    "        # Determine data type from filename\n",
    "        if 'uint32' in filename:\n",
    "            fmt = '<I'\n",
    "            item_size = 4\n",
    "        elif 'uint64' in filename:\n",
    "            fmt = '<Q'\n",
    "            item_size = 8\n",
    "        else:\n",
    "            raise ValueError(\"Filename must contain 'uint32' or 'uint64'\")\n",
    "        \n",
    "        # Read all data\n",
    "        data = []\n",
    "        for i in range(num_items):\n",
    "            item_bytes = f.read(item_size)\n",
    "            if len(item_bytes) < item_size:\n",
    "                break\n",
    "            value = struct.unpack(fmt, item_bytes)[0]\n",
    "            data.append((value, i))\n",
    "    \n",
    "    return RMITrainingData(data)\n",
    "\n",
    "def create_synthetic_data(n: int, distribution: str = 'uniform') -> RMITrainingData:\n",
    "    \"\"\"Create synthetic sorted data for testing\"\"\"\n",
    "    \n",
    "    if distribution == 'uniform':\n",
    "        keys = np.sort(np.random.randint(0, n * 10, size=n))\n",
    "    elif distribution == 'normal':\n",
    "        keys = np.sort(np.random.normal(n * 5, n, size=n).astype(int))\n",
    "        keys = np.maximum(keys, 0)  # Ensure non-negative\n",
    "    elif distribution == 'lognormal':\n",
    "        keys = np.sort(np.random.lognormal(10, 2, size=n).astype(int))\n",
    "    elif distribution == 'exponential':\n",
    "        keys = np.sort(np.random.exponential(n / 10, size=n).astype(int))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distribution: {distribution}\")\n",
    "    \n",
    "    # Create (key, position) pairs\n",
    "    data = [(int(k), i) for i, k in enumerate(keys)]\n",
    "    return RMITrainingData(data)\n",
    "\n",
    "def benchmark_rmi(rmi: TrainedRMI, test_keys: List[int], actual_data: List[Tuple[int, int]]):\n",
    "    \"\"\"\n",
    "    Benchmark RMI performance\n",
    "    From: general benchmarking approach\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Benchmarking RMI ===\")\n",
    "    \n",
    "    # Create sorted array for binary search comparison\n",
    "    sorted_keys = [k for k, _ in actual_data]\n",
    "    \n",
    "    # Test predictions\n",
    "    total_search_range = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for key in test_keys:\n",
    "        pred, err = rmi.predict(key)\n",
    "        \n",
    "        # Check if prediction is within error bound\n",
    "        lower = max(0, pred - err)\n",
    "        upper = min(len(actual_data) - 1, pred + err)\n",
    "        total_search_range += (upper - lower + 1)\n",
    "        \n",
    "        # Find actual position\n",
    "        actual_pos = bisect.bisect_left(sorted_keys, key)\n",
    "        \n",
    "        if lower <= actual_pos <= upper:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    avg_search_range = total_search_range / len(test_keys)\n",
    "    accuracy = 100 * correct_predictions / len(test_keys)\n",
    "    \n",
    "    print(f\"Tested {len(test_keys)} keys\")\n",
    "    print(f\"Average search range: {avg_search_range:.2f}\")\n",
    "    print(f\"Prediction accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Avg log2(search range): {math.log2(avg_search_range + 1):.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'avg_search_range': avg_search_range,\n",
    "        'accuracy': accuracy,\n",
    "        'total_tested': len(test_keys)\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Main demonstration\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Demonstrate RMI training and usage\"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"RMI (Recursive Model Index) Implementation\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create synthetic dataset\n",
    "    print(\"\\n1. Creating synthetic dataset...\")\n",
    "    n = 1_000_000\n",
    "    data = create_synthetic_data(n, distribution='normal')\n",
    "    print(f\"Created {len(data)} data points\")\n",
    "    \n",
    "    # Train RMI with different configurations\n",
    "    configs = [\n",
    "        (\"linear,linear\", 1000),\n",
    "        (\"robust_linear,linear\", 1000),\n",
    "        (\"cubic,linear\", 1000),\n",
    "        (\"linear_spline,linear\", 1000),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_spec, branch_factor in configs:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"2. Training RMI: {model_spec} with branching factor {branch_factor}\")\n",
    "        print(f\"{'=' * 70}\")\n",
    "        \n",
    "        rmi = train(data.soft_copy(), model_spec, branch_factor)\n",
    "        \n",
    "        # Test on random keys\n",
    "        print(\"\\n3. Testing predictions...\")\n",
    "        test_keys = [data.get_key(i) for i in np.random.randint(0, len(data), size=1000)]\n",
    "        \n",
    "        benchmark_results = benchmark_rmi(rmi, test_keys, data.data)\n",
    "        \n",
    "        results.append({\n",
    "            'config': model_spec,\n",
    "            'branching_factor': branch_factor,\n",
    "            'build_time': rmi.build_time,\n",
    "            'avg_error': rmi.model_avg_error,\n",
    "            'max_error': rmi.model_max_error,\n",
    "            'avg_log2_error': rmi.model_avg_log2_error,\n",
    "            'avg_search_range': benchmark_results['avg_search_range']\n",
    "        })\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESULTS COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Config':<25} {'Branch':<8} {'Build(s)':<10} {'AvgErr':<10} {'MaxErr':<10} {'AvgLog2':<10} {'SearchRng':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for r in results:\n",
    "        print(f\"{r['config']:<25} {r['branching_factor']:<8} {r['build_time']:<10.3f} \"\n",
    "              f\"{r['avg_error']:<10.2f} {r['max_error']:<10} {r['avg_log2_error']:<10.3f} \"\n",
    "              f\"{r['avg_search_range']:<10.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Done!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73e9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
